\chapter{Data Mining}

\begin{figure}[!htbp]
  \begin{center}
    \leavevmode
    \ifpdf
    \includegraphics[scale = 1]{mapDataMining}
    \else
    \includegraphics[bb = 92 86 545 742, height=6in]{mapDataMining}
    \fi
    \caption{Chapter structure}
    \label{FigStructure}
  \end{center}
\end{figure}

\label{chap:dataMining}
\noindent Virtual Observatory may be seen as data infrastructure. It enables
astronomers to get data more easily in a uniform way. But there is
another and even bigger problem now. How to deal with huge amount of
data? Can we change the problem to opportunity? Can we discover new
phenomena, new types of objects or exploit natural groups in the data?
Data Mining and related techniques are created exactly for such
purposes. Used correctly, it can be powerful approach, promising
scientific advance. On the other hand this field is very complex with
dozens of different methods and algorithms. This form needs and
opportunity for interdisciplinary cooperation with Data Mining
experts. This can be very beneficial for both fields, providing
astronomers with interesting methods for data analysis and computer
scientist with the large ammout of quality data.

\section{Supervised Methods}
These methods are also known as predictive\citep{ball2010data}. They
rely on training set with known target property. This set must be
representative. The selected method is trained on that set and the
result is then used on data for which the target property is not
known. Among supervised method are classification, regression, anomaly
detection and others.

\subsection{Decision Tree (DT)}
DT Is an example of supervised classification. Based on final number of
data $(x^{(1)},\ldots,x^{(p)})$ with known class $C_1,\ldots, C_m$
classifier is created, i.e. mapping $f$ classifying any $x \in
\mathcal{X}, f:\mathcal{X}\rightarrow \mathcal{Y}$, where
$\mathcal{X}$ is a set of possible input vectors and $\mathcal{Y}$ is
a set which values represent classes $C_1,\ldots, C_m$ (for example
$\mathcal{Y} = {1,\ldots,m}$). The model is constructed based on
training set as a tree structure, where leaves represent
classifications and branches conjunctions of features that lead to
those classifications. The main advantages of DT are:

\begin{itemize}
\item Simple to understand and interpret.
\item Able to handle both numerical and categorical data.
\item Internal details are easily seen (white box model).
\item Perform well with large data in a short time.
\end{itemize}

\noindent In pseudo-code, the general algorithm for building decision
trees is demonstrated below \citep{kotsiantis2007supervised}:
\begin{enumerate}
\item Check for base cases
\item For each attribute A


  \hspace{1cm} Find the normalized information gain from splitting on A
  % \begin{itemize}
  % \item Find the normalized information gain from splitting on A
  % \end{itemize}
\item Let "A best" be the attribute with the highest normalized information gain
\item Create a decision node that splits on "{A best}"
\item Recur on the sublists obtained by splitting on "{A best}",
  and add those nodes as children of node
\end{enumerate}

In practical part of this work algorithms C4.5 was used for several
reasons: Its code is available and free implementations exist (J48 in
Weka) and it is de-facto standard. The key question of DT algorithm is
how to choose attribute for splitting the tree. C4.5 uses measure
based on information entropy:

\begin{equation}
  \label{eq:entropy}
  H = -\sum_{i=1}^T {p_t \log_2 p_t},
\end{equation}
where $p(x_i)$ is probability of occurrence of class $t$ and $T$ is
the number of classes \citep{berka2003dobyvani}. After the tree is
created it is optimized by pruning, which prevents over-fitting.

%\subsubsection{Pruning}         
\subsubsection{Cross-validation}
The quality of the training set is crucial to good results. The amount
of data for testing is always limited. In general, one cannot be sure
whether a sample is representative. If for example certain group is
missing, one could not expect a classifier learned from such data to
perform well on the examples of that class. One of the technique used
here is cross-validation.

The data are divided into fixed number of partitions (folds) where
each in turn is used for testing while the reminder is used for
training. Finally, the error estimates of partitions are averaged to
yield an overall error. The standard way is to use 10-fold
cross-validation. This number is a result of tests on numerous data
sets \citep{witten2005data}

\subsubsection{Example: Classifying Galaxies, Stars and QSO using Color
Indices}

There is an example of classifying galaxies stars and QSO based on
photometric properties using Decision Tree algorithm J48 (C4.5 in
Weka). The data come from SDSS (Sloan Digital Sky Survey)
DR7. Altogether 298 objects were used (100 stars, 99 galaxies, 99
QSOs). SDSS filters u,g,r,i were used as parameters. Data were
obtained using SQL query from SDSS CAS.

\begin{table}[ht]
  \centering
  \small
     \begin{tabular}[ht]{l c}
     \toprule
     Filter & Effective wavelength [$\,\textrm{\AA}$] \\
     \midrule
     Ultraviolet (u) & 3543 \\
     Green (g) & 4770\\
     Red (r) & 6231\\
     Near Infrared (i) & 7625\\
     Infrared (z) & 9134 \\
     \bottomrule
   \end{tabular}
  \caption{SDSS photometric system \citep{fukugita1996sloan} }
  \label{tab:SDSSFilter}
\end{table}




\begin{lstlisting}
SELECT TOP 100 u-g,g-r,r-i,s.specClass
FROM PhotoPrimary p join SpecPhotoAll s on p.objid=s.objid 
WHERE s.specClass in (1)
AND u between 18 and 19
UNION all
SELECT top 100 u-g,g-r,r-i,s.specClass
FROM PhotoPrimary p join SpecPhotoAll s on p.objid=s.objid 
WHERE s.specClass in (2)
AND u between 18 and 19
UNION all
SELECT top 100 u-g,g-r,r-i,s.specClass
FROM PhotoPrimary p join SpecPhotoAll s on p.objid=s.objid 
WHERE s.specClass in (3)
AND u between 18 and 19
\end{lstlisting}

The following listing shows the result of classification. The
classifier was able to distinguish 95\% of the processed objects.



\begin{lstlisting}
Correctly Classified Instances         277               92.953  %
Incorrectly Classified Instances        21                7.047  %
Kappa statistic                          0.8943
Mean absolute error                      0.0736
Root mean squared error                  0.2096
Relative absolute error                 16.5627 %
Root relative squared error             44.4707 %
Total Number of Instances              298
\end{lstlisting}

The big advantage of Decision Trees over black box algorithms (such as
Neural Network) is that one could understand the classification
process. The decision tree generated by Weka for this example is
following:

\begin{lstlisting}
ug <= 0.663668
|   gr <= -0.191208: 1 (7.0)
|   gr > -0.191208: 3 (104.0/5.0)
ug > 0.663668
|   ri <= 0.285854: 1 (88.0/5.0)
|   ri > 0.285854
|   |   ri <= 0.314657
|   |   |   gr <= 0.692108: 2 (6.0)
|   |   |   gr > 0.692108: 1 (3.0)
|   |   ri > 0.314657: 2 (90.0/2.0)
\end{lstlisting}

The useful tool for understanding how classifier was successful on
individual classes is the confusion matrix. Columns show how the
object was classified and the row what is his actual class. In this
example QSO were classified correctly in 97 of 99 cases. Distinction
between stars and galaxies are a bit worse and the algorithm
classified 7 galaxies incorrectly as stars and 7 stars were confused
with galaxies. Five stars were incorrectly classified as QSO.
 
\begin{lstlisting}
  s  g  q   <-- classified as
 88  7  5 |  s
  7 92  0 |  g
  2  0 97 |  q
\end{lstlisting}
 
\begin{figure}[!htbp]
%      \begin{center}
        \leavevmode
        \ifpdf
        \includegraphics[scale = .7]{starsGalaxiesQSO}
        \else
        \includegraphics[bb = 92 86 545 742, height=6in]{starsGalaxiesQSO}
        \fi
        \caption{Color Diagram of the problem. It shows that individual
          object classes occupies different regions in the diagram }
        \label{FigStarsGalaxiesQSO}
 %     \end{center}
\end{figure}

%\clearpage


% \begin{lstlisting}
% Dataset                   (1) trees.J4 | (2) bayes (3) meta. (4) lazy. (5) lazy. (6) rules
% ------------------------------------------------------------------------------------------
% Galaxy-Star-QSO          (100)   93.02 |   87.98 *   94.40     94.19     94.69     33.56 *
% STAR-B-BE                (100)   70.78 |   68.11 *   72.02     65.22 *   69.67     52.85 *
% STAR-AB                  (100)   69.66 |   64.96 *   69.79     65.97 *   70.45     50.76 *
% STAR-BE-O                (100)   99.28 |   72.39 *   93.86     85.28 *   96.71     56.92 *
% ------------------------------------------------------------------------------------------
%                                (v/ /*) |   (0/0/4)   (0/4/0)   (0/1/3)   (0/4/0)   (0/0/4)
% Key:
% (1) trees.J48 '-C 0.25 -M 2' -217733168393644444
% (2) bayes.NaiveBayes '' 5995231201785697655
% (3) meta.RotationForest '-G 3 -H 3 -P 50 -F \"unsupervised.attribute.PrincipalComponents -R 1.0 -A 5 -M -1\" -S 1 -I 10 -W trees.J48 -- -C 0.25 -M 2' -3255631880798499936
% (4) lazy.IBk '-K 1 -W 0 -A \"weka.core.neighboursearch.LinearNNSearch -A \\\"weka.core.EuclideanDistance -R first-last\\\"\"' -3080186098777067172
% (5) lazy.KStar '-B 20 -M a' 332458330800479083
% (6) rules.ZeroR '' 48055541465867954
% \end{lstlisting}

% \subsection{Support Vector Machine (SVM)} 

% \section{Unsupervised Methods}
\section{Data Mining Tools}
There are many open source projects related to Machine Learning and
Data Mining. I would like to mention those which were used during
experiments related to this work.

\subsection{Weka}

Weka is a collection of machine learning algorithms developed at
University of Waikato, New Zealand. It includes functions for
preprocessing, clustering, classification, regression, visualization,
and feature selection. Originally designed as a tool for analyzing
data from agricultural domains became extremely popular in data mining
community because of its quality, openness, perfect documentation, and
multi-platform implementation. Weka can be obtained at
\url{http://www.cs.waikato.ac.nz/~ml/weka/}



\subsection{SVM lib}
It is the library implementing Support Vector Machine with following properties
\begin{itemize}
    \item Different SVM formulations
    \item Efficient multi-class classification
    \item Cross validation for model selection
    \item Probability estimates
    \item Various kernels (including precomputed kernel matrix)
    \item Weighted SVM for unbalanced data
    \item Both C++ and Java sources
    \item GUI demonstrating SVM classification and regression
    \item Python, R, MATLAB, Perl, Ruby, Weka, Common LISP, CLISP,
      Haskell, and LabVIEW, interfaces. C\# .NET code and CUDA
      extension is available.  It's also included in some data mining
      environments: RapidMiner and PCP.
    \item Automatic model selection which can generate contour of
      cross valiation accuracy.
\end{itemize}

The project is hosted on
\url{http://www.csie.ntu.edu.tw/~cjlin/libsvm/}.  The part of this
project is useful and well written practical guide to SVM
classification.

\subsection{DAME}
The project DAME (Data Mining \& Exploration) is a great example of
full understanding of the paradigm shift in astronomy. The project
implements Neural Networks and Support Vector Machines algorithms and
it is VO-compatible. The documentation includes scientific use cases,
masters and PhD thesis and lectures. As it is typical in these
projects it exceeds its original domain of astronomical data into
general platform. The project is available at:
\url{http://dame.dsf.unina.it/}

