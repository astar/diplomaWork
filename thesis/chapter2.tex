\chapter{Data Mining}

\begin{figure}[!htbp]
  \begin{center}
    \leavevmode
    \ifpdf
    \includegraphics[scale = 1]{mapDataMining}
    \else
    \includegraphics[bb = 92 86 545 742, height=6in]{mapDataMining}
    \fi
    \caption{Chapter structure}
    \label{FigStructure}
  \end{center}
\end{figure}

\label{chap:dataMining}
Virtual Observatory may be seen as data infrastructure. It enables
astronomers to get data more easily in a uniform way. But there is
another and even bigger problem now. How to deal with huge amount of
data? Can we change the problem to opportunity? Can we discover new
phenomena, new types of objects or exploit natural groups in the data?
Data Mining and related techniques are created exactly for such
purposes. Used correctly, it can be powerful approach, promising
scientific advance. On the other side this field is very complex with
dozens of different methods and algorithms. This forms needs and
opportunity for interdisciplinary cooperation with Data Mining
experts. This can be very beneficially for both fields, providing
astronomers with interesting methods for data analysis and computer
scientist with large ammout of quality data.

\section{Supervised Methods}
These methods are also known as predictive\cite{ball2010data}. They
rely on training set with known target property. This set must be
representative. The selected method is trained on that set and the
result is then used on data for which the target property is not
known. Among supervised method are classification, regression, anomaly
detection and others.

\subsection{Decision Tree (DT)}
Is an example of supervised classification. Based on final number of
data $(x^{(1)},\ldots,x^{(p)})$ with known class $C_1,\ldots, C_m$
classifier is created, i.e. image $f$ classifying any $x \in
\mathcal{X}, f:\mathcal{X}\rightarrow \mathcal{Y}$, where
$\mathcal{X}$ is a set of possible input vectors and $\mathcal{Y}$ is
a set which values represent classes $C_1,\ldots, C_m$ (for example
$\mathcal{Y} = {1,\ldots,m}$). The model is constructed based on
training set as a tree structure, where leaves represent
classifications and branches conjunctions of features that lead to
those classifications. The main advantages of DT are:

\begin{itemize}
\item Simple to understand and interpret.
\item Able to handle both numerical and categorical data.
\item Uses a white box model.
\item Perform well with large data in a short time.
\end{itemize}

In pseudo-code, the general algorithm for building decision trees is
\cite{kotsiantis2007supervised}:
\begin{enumerate}
\item Check for base cases
\item For each attribute a
  \begin{itemize}
  \item Find the normalized information gain from splitting on a
  \end{itemize}
\item Let "a best" be the attribute with the highest normalized information gain
\item Create a decision node that splits on "a best"
\item Recur on the sublists obtained by splitting on "a best", and add
  those nodes as children of node
\end{enumerate}

Furthermore algorithms C4.5 is described for several reasons: Its code
is available and free implementations exist (J48 in Weka), is de-facto
standard in classification using DT, is used in practical part of this
work. The key question of DT algorithm is how to choose attribute for
splitting the tree. C4.5 Uses measures based on information entropy:

\begin{equation}
  \label{eq:entropy}
  H(X) = -\sum_{i=1}^n {p(x_i) \log_2 p(x_i)},
\end{equation}
where $p(x_i)$ is probability of occurrence of class $i$ and $n$ is the
number of classes.

After the tree is created it is optimized by pruning, which prevents
over-fitting.

%\subsubsection{Pruning}         
\subsubsection{Cross-validation}
The quality of the training set is crucial to good results. The amount
of data for testing is always limited. In general, one cannot be sure
whether a sample is representative. If for example certain group is
missing, one could not expect a classifier learned from such data to
perform well on the examples s of that class. One of the technique used
here is cross-validation.

The data is divided into fixed number of partitions and each in turn
is used for testing and the reminder is used for training. Finally,
the number of partitions error estimates are averaged to yield an
overall error. The standard is to used 10-fold cross-validation. This
number is a result of tests on numerous data sets \cite{witten2005data}

\subsubsection{Example: Classifying Galaxies Stars and QSO}
There is an example of classifying Galaxies Stars and QSO based on
photometric properties using Decision Tree algorithm J48 (C4.5 in
Weka). The data come from SDSS (Sloan Digital Sky Survey) DR7. 298
Objects were used (100 Stars, 99 Galaxies, 99 QSO). SDSS Filters
u,g,r,i were used as parameters. Data were obtained using SQL query
from SDSS CAS.

\begin{lstlisting}
SELECT TOP 100 u-g,g-r,r-i,s.specClass
FROM PhotoPrimary p join SpecPhotoAll s on p.objid=s.objid 
WHERE s.specClass in (1)
AND u between 18 and 19
UNION all
SELECT top 100 u-g,g-r,r-i,s.specClass
FROM PhotoPrimary p join SpecPhotoAll s on p.objid=s.objid 
WHERE s.specClass in (2)
AND u between 18 and 19
UNION all
SELECT top 100 u-g,g-r,r-i,s.specClass
FROM PhotoPrimary p join SpecPhotoAll s on p.objid=s.objid 
WHERE s.specClass in (3)
AND u between 18 and 19
\end{lstlisting}

The following listing shows the result of classification. The
classifier was able to distinguish 95\% of the processed objects.

\begin{table}[ht]
  \centering
  \small
     \begin{tabular}[ht]{l r@{,}l r@{,}l l l}
     \toprule
     Filter & Wavelength [$\AA$] \\
     \midrule
     Ultraviolet (u) & 3543 \\
     Green (g) & 4770\\
     Red (r) & 6231\\
     Near Infrared (i) & 7625\\
     Infrared (z) & 9134 \\
     \bottomrule
   \end{tabular}
  \caption{SDSS Filters}
  \label{tab:SDSSFilter}
\end{table}


\begin{lstlisting}
Correctly Classified Instances          96               95.0495 %
Incorrectly Classified Instances         5                4.9505 %
Kappa statistic                          0.9257
Mean absolute error                      0.0669
Root mean squared error                  0.1778
Relative absolute error                 15.0587 %
Root relative squared error             37.6973 %
Total Number of Instances              101     
\end{lstlisting}

The big advantage of Decision Trees over black box algorithms (such as
Neural Network) is that one could understand the classification
process. The decision tree generated for this example is following:

\begin{lstlisting}
  ug <= 0.663668
|   gr <= -0.191208: 1 (7.0)
|   gr > -0.191208: 3 (104.0/5.0)
ug > 0.663668
|   ri <= 0.285854: 1 (88.0/5.0)
|   ri > 0.285854
|   |   ri <= 0.314657
|   |   |   gr <= 0.692108: 2 (6.0)
|   |   |   gr > 0.692108: 1 (3.0)
|   |   ri > 0.314657: 2 (90.0/2.0)
\end{lstlisting}

Useful tool for understanding how classifier was successful on
individual classes is the confusion matrix. Columns show how the
object was classified and the row what is his actual class. In this
example QSO were classified correctly in 100\% cases. Distinction
between stars and galaxies are a bit worse and the algorithm classify
2 galaxies incorrectly as stars and two stars were confused with
galaxies. One stars was incorrectly classified as QSO.
 
\begin{lstlisting}
  s  g  q   <-- classified as
 30  2  1 |  s 
  2 33  0 |  g 
  0  0 33 |  q 
\end{lstlisting}
 
\begin{figure}[!htbp]
%      \begin{center}
        \leavevmode
        \ifpdf
        \includegraphics[scale = .7]{starsGalaxiesQSO}
        \else
        \includegraphics[bb = 92 86 545 742, height=6in]{starsGalaxiesQSO}
        \fi
        \caption{Color Diagram of the problem.It shows that individual
          object classes occupy different regions in the diagram }
        \label{FigStarsGalaxiesQSO}
 %     \end{center}
\end{figure}

\clearpage


\begin{lstlisting}
Dataset                   (1) trees.J4 | (2) bayes (3) meta. (4) lazy. (5) lazy. (6) rules
------------------------------------------------------------------------------------------
Galaxy-Star-QSO          (100)   93.02 |   87.98 *   94.40     94.19     94.69     33.56 *
STAR-B-BE                (100)   70.78 |   68.11 *   72.02     65.22 *   69.67     52.85 *
STAR-AB                  (100)   69.66 |   64.96 *   69.79     65.97 *   70.45     50.76 *
STAR-BE-O                (100)   99.28 |   72.39 *   93.86     85.28 *   96.71     56.92 *
------------------------------------------------------------------------------------------
                               (v/ /*) |   (0/0/4)   (0/4/0)   (0/1/3)   (0/4/0)   (0/0/4)
Key:
(1) trees.J48 '-C 0.25 -M 2' -217733168393644444
(2) bayes.NaiveBayes '' 5995231201785697655
(3) meta.RotationForest '-G 3 -H 3 -P 50 -F \"unsupervised.attribute.PrincipalComponents -R 1.0 -A 5 -M -1\" -S 1 -I 10 -W trees.J48 -- -C 0.25 -M 2' -3255631880798499936
(4) lazy.IBk '-K 1 -W 0 -A \"weka.core.neighboursearch.LinearNNSearch -A \\\"weka.core.EuclideanDistance -R first-last\\\"\"' -3080186098777067172
(5) lazy.KStar '-B 20 -M a' 332458330800479083
(6) rules.ZeroR '' 48055541465867954
\end{lstlisting}

% \subsection{Support Vector Machine (SVM)} 

% \section{Unsupervised Methods}
\section{Existing Projects}
There are many open source projects related to Machine Learning and
Data Mining. I would like to mention those which were used during
experiments related to this work.

\subsection{Weka}

Weka is a collection of machine learning algorithms developed at
University of Waikato, New Zealand. It includes functions for
preprocessing, clustering, classification, regression, visualization,
and feature selection. Originally designed as a tool for analyzing
data from agricultural domains become extremely popular in data mining
community because of its quality, openness, perfect documentation, and
multi-platform implementation. Weka can be obtained at
\url{http://www.cs.waikato.ac.nz/~ml/weka/}



\subsection{SVM lib}
Is library implementing Support Vector Machine with following properties
\begin{itemize}
    \item Different SVM formulations
    \item Efficient multi-class classification
    \item Cross validation for model selection
    \item Probability estimates
    \item Various kernels (including precomputed kernel matrix)
    \item Weighted SVM for unbalanced data
    \item Both C++ and Java sources
    \item GUI demonstrating SVM classification and regression
    \item Python, R, MATLAB, Perl, Ruby, Weka, Common LISP, CLISP,
      Haskell, and LabVIEW, interfaces. C\# .NET code and CUDA
      extension is available.  It's also included in some data mining
      environments: RapidMiner and PCP.
    \item Automatic model selection which can generate contour of
      cross valiation accuracy.
\end{itemize}

The project is hosted on
\url{http://www.csie.ntu.edu.tw/~cjlin/libsvm/}.  The part of this
project is useful and well written practical guide to SVM
classification.

\subsection{DAME}

Is great example of full understanding of the paradigm shift in
astronomy. The project implements Neural Networks and Support Vector
Machines algorithms and it is VO-compatible. The documentation includes
scientific use cases, masters and PhD thesis and lectures. As it is
typical in these projects it exceeds its original domain of
astronomical data into general platform. The projects is available at
\url{http://dame.dsf.unina.it/}

